# üß† QUEEN BEE : ARCHITECTURE DU MOTEUR LLM (UNIFIED ENGINE)

Cette architecture d√©crit l'int√©gration du moteur multi-provider d'OpenClaw dans Queen Bee pour remplacer les mocks actuels.

## 1. VISION G√âN√âRALE
L'objectif est de d√©coupler l'orchestration de Queen Bee du SDK sp√©cifique d'un fournisseur. Nous utilisons une couche d'abstraction inspir√©e d'OpenClaw pour supporter les mod√®les Cloud, Locaux et d'Entreprise.

```mermaid
graph TD
    Hive[HiveOrchestrator] --> Unified[UnifiedLLMService]
    Unified --> Adapter[LLMProviderAdapter]
    Adapter --> OpenAI[OpenAI API]
    Adapter --> Anthropic[Anthropic API]
    Adapter --> Gemini[Gemini API]
    Adapter --> Local[Local / Enterprise Gateway]
    Local --> Ollama[Ollama]
    Local --> Internal[Internal GPT-OSS]
```

## 2. CONFIGURATION DES MOD√àLES LOCAUX
Pour utiliser un mod√®le local (ex: Ollama ou un proxy d'entreprise), la configuration doit se faire via `config.yaml` ou `models.json`.

### Exemple de configuration pour Ollama
```yaml
models:
  providers:
    ollama:
      baseUrl: "http://localhost:11434/v1"
      api: "openai-completions"
      models:
        - id: "llama3:latest"
          name: "Llama 3 Local"
          contextWindow: 8192
```

### Exemple pour une URL d'entreprise (Proxy)
```yaml
models:
  providers:
    enterprise-proxy:
      baseUrl: "https://proxy.internal.corp/v1"
      api: "openai-completions"
      apiKey: "${INTERNAL_TOKEN}"
      models:
        - id: "gpt-oss-120b"
          name: "Corporate GPT"
```

## 3. PIPELINE D'EX√âCUTION (AGENTIC LOOP)
Le `AutonomousRunner.ts` utilise la boucle **Think -> Act -> Observe** :

1.  **Think** : Le mod√®le re√ßoit le contexte (Project Tree, README, TASKS.md) et g√©n√®re un plan ou un appel d'outil.
2.  **Act** : `ToolExecutor.ts` intercepte l'appel (ex: `write_file`) et l'ex√©cute via `NativeFSManager`.
3.  **Observe** : Le r√©sultat de l'ex√©cution est renvoy√© au mod√®le pour valider l'√©tape ou corriger une erreur.

## 4. GESTION DES IDENTIT√âS ET CL√âS
- **Cloud** : Utilise les cl√©s stock√©es dans `.env` ou via OAuth dans `AccountStateManager`.
- **Local** : Priorit√© au `baseUrl` d√©fini dans la config locale pour √©viter les fuites de donn√©es vers le cloud.
- **S√©curit√©** : Les jetons sont chiffr√©s et stock√©s localement sur la machine de l'utilisateur.

## 5. STANDARDISATION DES I/O
Toutes les r√©ponses des providers sont normalis√©es en format **OpenResponses** (ou JSON structur√©) pour que l'orchestrateur puisse traiter les r√©sultats de mani√®re agnostique au mod√®le utilis√©.
